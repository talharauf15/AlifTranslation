{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch sentencepiece transformers datasets gradio ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:55:32.004162Z","iopub.execute_input":"2025-03-02T06:55:32.004464Z","iopub.status.idle":"2025-03-02T06:55:43.664574Z","shell.execute_reply.started":"2025-03-02T06:55:32.004431Z","shell.execute_reply":"2025-03-02T06:55:43.663558Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting gradio\n  Downloading gradio-5.20.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.7.2 (from gradio)\n  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nCollecting markupsafe~=2.0 (from gradio)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a2)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.2->gradio) (14.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.20.0-py3-none-any.whl (62.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.0-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\nSuccessfully installed fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.0 gradio-client-1.7.2 groovy-0.1.2 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.9 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 uvicorn-0.34.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the Arabic-to-English dataset\ndataset = load_dataset('Helsinki-NLP/tatoeba_mt', 'ara-eng')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:55:43.666071Z","iopub.execute_input":"2025-03-02T06:55:43.666348Z","iopub.status.idle":"2025-03-02T06:55:56.721612Z","shell.execute_reply.started":"2025-03-02T06:55:43.666324Z","shell.execute_reply":"2025-03-02T06:55:56.720680Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f56545c6e5241bfa139870cc3acf389"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba_mt.py:   0%|          | 0.00/15.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"184f8904d78b4de6b33e9d869e278ae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a4e80f62e64be88ba7a6372ff00923"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for Helsinki-NLP/tatoeba_mt contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Helsinki-NLP/tatoeba_mt.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"tatoeba-test.ara-eng.tsv:   0%|          | 0.00/938k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c215ce2b910a4308aa325ea47f8675c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba-dev.ara-eng.tsv:   0%|          | 0.00/1.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f12171c399a451197320c8a77dbcbdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10304 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a37a293e9e74d8cbf95d1de796580a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/19528 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aeb6b20e66e4a26bec1942910db43ad"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load pre-trained tokenizers for Arabic and English\ntokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ar-en\")\n\ndef preprocess_function(examples):\n     # Extract source (Arabic) and target (English) texts\n    arabic_texts = examples['sourceString']\n    english_texts = examples['targetString']\n    \n    # Tokenize the Arabic texts (inputs) and English texts (labels)\n    model_inputs = tokenizer(arabic_texts, max_length=128, truncation=True, padding='max_length')\n    labels = tokenizer(english_texts, max_length=128, truncation=True, padding='max_length')\n    \n    # Add labels to the model inputs\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n# Tokenize the dataset\ntokenized_datasets = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:55:56.723491Z","iopub.execute_input":"2025-03-02T06:55:56.723744Z","iopub.status.idle":"2025-03-02T06:56:18.083408Z","shell.execute_reply.started":"2025-03-02T06:55:56.723721Z","shell.execute_reply":"2025-03-02T06:56:18.082664Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961d7155c9d8479da39504ea88463092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea3d751b397f4c3ba23ff639b57e96b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6ec96bf45a54f439e7a9d3ebebfe315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/917k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35d0675e21548c78c930160d1083602"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55a53ac31cc441eb8381064fb353a41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e3216e0bed94219a7244f4dcb27c044"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10304 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3363450bd104823a1da31601c7acfed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/19528 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ccf1be2c75b404783baf205cd5c1a7a"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\n# Load a pre-trained model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ar-en\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:56:18.084480Z","iopub.execute_input":"2025-03-02T06:56:18.084803Z","iopub.status.idle":"2025-03-02T06:56:34.550907Z","shell.execute_reply.started":"2025-03-02T06:56:18.084779Z","shell.execute_reply":"2025-03-02T06:56:34.549831Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b621d115c8047688fd1e0f429a39525"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1643eed34bca440386553222e578bd46"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\n# Data collator for dynamic padding\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:56:34.552099Z","iopub.execute_input":"2025-03-02T06:56:34.553081Z","iopub.status.idle":"2025-03-02T06:56:36.121421Z","shell.execute_reply.started":"2025-03-02T06:56:34.553039Z","shell.execute_reply":"2025-03-02T06:56:36.120753Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    report_to=\"none\",  # Disables WandB logging\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_total_limit=2,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:56:36.122286Z","iopub.execute_input":"2025-03-02T06:56:36.122508Z","iopub.status.idle":"2025-03-02T06:56:36.247102Z","shell.execute_reply.started":"2025-03-02T06:56:36.122488Z","shell.execute_reply":"2025-03-02T06:56:36.246152Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Initialize the Trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"validation\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:56:36.248069Z","iopub.execute_input":"2025-03-02T06:56:36.248371Z","iopub.status.idle":"2025-03-02T06:56:36.537444Z","shell.execute_reply.started":"2025-03-02T06:56:36.248336Z","shell.execute_reply":"2025-03-02T06:56:36.536778Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-9e791347dfd9>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Rest of your code\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T06:56:36.538211Z","iopub.execute_input":"2025-03-02T06:56:36.538541Z","iopub.status.idle":"2025-03-02T07:10:27.791183Z","shell.execute_reply.started":"2025-03-02T06:56:36.538509Z","shell.execute_reply":"2025-03-02T07:10:27.790291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3663' max='3663' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3663/3663 13:50, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.175700</td>\n      <td>0.135698</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.130400</td>\n      <td>0.118536</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.112200</td>\n      <td>0.114894</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[62833]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3663, training_loss=0.18308026758725612, metrics={'train_runtime': 830.8478, 'train_samples_per_second': 70.511, 'train_steps_per_second': 4.409, 'total_flos': 1985901810941952.0, 'train_loss': 0.18308026758725612, 'epoch': 3.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"**Evaluate the Model**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test dataset\neval_results = trainer.evaluate(tokenized_datasets[\"test\"])\n\n# Print evaluation results\nprint(\"Evaluation Results:\", eval_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:10:27.793119Z","iopub.execute_input":"2025-03-02T07:10:27.793405Z","iopub.status.idle":"2025-03-02T07:11:08.031868Z","shell.execute_reply.started":"2025-03-02T07:10:27.793383Z","shell.execute_reply":"2025-03-02T07:11:08.031011Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='644' max='644' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [644/644 00:40]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.11489422619342804, 'eval_runtime': 40.2302, 'eval_samples_per_second': 256.126, 'eval_steps_per_second': 16.008, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Calculate BLEU Score**","metadata":{}},{"cell_type":"code","source":"!pip install sacrebleu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:19:39.972549Z","iopub.execute_input":"2025-03-02T07:19:39.973091Z","iopub.status.idle":"2025-03-02T07:19:44.029244Z","shell.execute_reply.started":"2025-03-02T07:19:39.973045Z","shell.execute_reply":"2025-03-02T07:19:44.028166Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import sacrebleu\n\n# Move model to GPU\nmodel = model.to(\"cuda\")\n\n# Function to generate translations\ndef generate_translations(model, tokenizer, dataset):\n    translations = []\n    references = []\n    \n    for example in dataset:\n        # Tokenize the input Arabic text and move to GPU\n        inputs = tokenizer(example[\"sourceString\"], return_tensors=\"pt\", truncation=True, padding=True)\n        inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}  # Move inputs to GPU\n        \n        # Generate translation\n        translated_tokens = model.generate(**inputs)\n        translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n        \n        # Append the translation and reference\n        translations.append(translated_text)\n        references.append([example[\"targetString\"]])  # Wrap in a list for sacrebleu\n    \n    return translations, references\n\n# Generate translations for the test dataset\ntranslations, references = generate_translations(model, tokenizer, tokenized_datasets[\"test\"])\n\n# Calculate BLEU score\nbleu_score = sacrebleu.corpus_bleu(translations, references)\nprint(\"BLEU Score:\", bleu_score.score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:22:20.413370Z","iopub.execute_input":"2025-03-02T07:22:20.413737Z","iopub.status.idle":"2025-03-02T07:46:02.577175Z","shell.execute_reply.started":"2025-03-02T07:22:20.413709Z","shell.execute_reply":"2025-03-02T07:46:02.576370Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 32.46679154750989\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"**Calculate Perplexity**","metadata":{}},{"cell_type":"code","source":"import torch\n\nperplexity = torch.exp(torch.tensor(eval_results[\"eval_loss\"]))\nprint(\"Perplexity:\", perplexity.item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:54:07.161928Z","iopub.execute_input":"2025-03-02T07:54:07.162241Z","iopub.status.idle":"2025-03-02T07:54:07.234425Z","shell.execute_reply.started":"2025-03-02T07:54:07.162218Z","shell.execute_reply":"2025-03-02T07:54:07.233562Z"}},"outputs":[{"name":"stdout","text":"Perplexity: 1.121754765510559\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**Calculate Accuracy**","metadata":{}},{"cell_type":"markdown","source":"***Word-Level Accuracy***","metadata":{}},{"cell_type":"code","source":"def calculate_word_level_accuracy(translations, references):\n    correct = 0\n    total = 0\n    \n    for pred, ref in zip(translations, references):\n        pred_words = pred.split()\n        ref_words = ref[0].split()  # References are wrapped in a list\n        \n        # Count correct words\n        for pred_word, ref_word in zip(pred_words, ref_words):\n            if pred_word == ref_word:\n                correct += 1\n        total += len(ref_words)\n    \n    accuracy = (correct / total) * 100\n    return accuracy\n\n# Calculate word-level accuracy\nword_accuracy = calculate_word_level_accuracy(translations, references)\nprint(\"Word-Level Accuracy:\", word_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T07:55:47.932981Z","iopub.execute_input":"2025-03-02T07:55:47.933333Z","iopub.status.idle":"2025-03-02T07:55:47.957544Z","shell.execute_reply.started":"2025-03-02T07:55:47.933309Z","shell.execute_reply":"2025-03-02T07:55:47.956565Z"}},"outputs":[{"name":"stdout","text":"Word-Level Accuracy: 47.17999169907614\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"***Sequence-Level Accuracy***","metadata":{}},{"cell_type":"code","source":"def calculate_sequence_level_accuracy(translations, references):\n    correct = 0\n    \n    for pred, ref in zip(translations, references):\n        if pred == ref[0]:  # Exact match\n            correct += 1\n    \n    accuracy = (correct / len(references)) * 100\n    return accuracy\n\n# Calculate sequence-level accuracy\nsequence_accuracy = calculate_sequence_level_accuracy(translations, references)\nprint(\"Sequence-Level Accuracy:\", sequence_accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T08:05:47.082743Z","iopub.execute_input":"2025-03-02T08:05:47.083085Z","iopub.status.idle":"2025-03-02T08:05:47.090458Z","shell.execute_reply.started":"2025-03-02T08:05:47.083058Z","shell.execute_reply":"2025-03-02T08:05:47.089494Z"}},"outputs":[{"name":"stdout","text":"Sequence-Level Accuracy: 21.321816770186334\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Visualize Results**","metadata":{}},{"cell_type":"code","source":"# Print some example translations\nfor i in range(5):  # Print first 5 examples\n    print(f\"Source: {tokenized_datasets['test'][i]['sourceString']}\")\n    print(f\"Reference: {tokenized_datasets['test'][i]['targetString']}\")\n    print(f\"Translation: {translations[i]}\")\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T08:06:25.067010Z","iopub.execute_input":"2025-03-02T08:06:25.067440Z","iopub.status.idle":"2025-03-02T08:06:25.078817Z","shell.execute_reply.started":"2025-03-02T08:06:25.067394Z","shell.execute_reply":"2025-03-02T08:06:25.077325Z"}},"outputs":[{"name":"stdout","text":"Source: فكرنا انه طبيعي لازم يتعاقب.\nReference: We thought it natural that he should be punished.\nTranslation: We think it's nature. He has to be punished.\n--------------------------------------------------\nSource: واحد اسمه هنري كال يريد يشوفك.\nReference: Someone named Henry wanted to see you.\nTranslation: One named Henry Kall wants to see you.\n--------------------------------------------------\nSource: أ أنت جائع ؟\nReference: Are you hungry?\nTranslation: Are you hungry?\n--------------------------------------------------\nSource: استجمع توم ما يكفي من الشجاعة لطلب علاوة .\nReference: Tom summoned up enough courage to ask for a raise.\nTranslation: Tom greated up enough for a bug.\n--------------------------------------------------\nSource: استدعيت اللجنة فوراً .\nReference: The committee was summoned at once.\nTranslation: The committee was immediately approached.\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Save the model and tokenizer\nmodel.save_pretrained(\"./arabic_to_english_model\")\ntokenizer.save_pretrained(\"./arabic_to_english_tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T08:09:37.270177Z","iopub.execute_input":"2025-03-02T08:09:37.270537Z","iopub.status.idle":"2025-03-02T08:09:38.393725Z","shell.execute_reply.started":"2025-03-02T08:09:37.270509Z","shell.execute_reply":"2025-03-02T08:09:38.392939Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"('./arabic_to_english_tokenizer/tokenizer_config.json',\n './arabic_to_english_tokenizer/special_tokens_map.json',\n './arabic_to_english_tokenizer/vocab.json',\n './arabic_to_english_tokenizer/source.spm',\n './arabic_to_english_tokenizer/target.spm',\n './arabic_to_english_tokenizer/added_tokens.json')"},"metadata":{}}],"execution_count":21}]}